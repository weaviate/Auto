{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hf_dataset': 'weaviate/WithoutRetrieval-SchemaSplit-Test-80',\n",
       " 'push_to_hub': 'substratusai/wgql-WithRetrieval-SchemaSplit-Train-80-3epochs'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "params = {}\n",
    "params_path = Path(\"/content/params.json\")\n",
    "if params_path.is_file():\n",
    "    with params_path.open(\"r\", encoding=\"UTF-8\") as params_file:\n",
    "        params = json.load(params_file)\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e628b32a92fc4e118cdb6f706db935b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7057f8f2a341473597cfad74287c469a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c88b171874a426f83510b98d74cc9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6b0377a3684e17bff1ad62a62f3fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a070a3908e0041819c15cbb66733e829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output', 'nlcommand', 'apiRef', 'apiRefPath', 'schema', 'schemaPath'],\n",
       "        num_rows: 825\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hf_dataset = params.get(\"hf_dataset\")\n",
    "if hf_dataset:\n",
    "    dataset = load_dataset(hf_dataset)\n",
    "else:\n",
    "    dataset = load_dataset(\"json\", data_files=\"/content/data/*.json*\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Instruction\n",
      "Your task is to write GraphQL for the Natural Language Query provided. Use the provided API reference and Schema to generate the GraphQL. The GraphQL should be valid for Weaviate.\n",
      "\n",
      "Only use the API reference to understand the syntax of the request.\n",
      "\n",
      "## Natural Language Query\n",
      "```text\n",
      "Show me the event name, description, year, significant impact, and the countries involved with their population for the top 10 historical events.\n",
      "```\n",
      "\n",
      "## Schema\n",
      "{\n",
      "\"classes\": [\n",
      "{\n",
      "\"class\": \"HistoricalEvent\",\n",
      "\"description\": \"Information about historical events\",\n",
      "\"vectorIndexType\": \"hnsw\",\n",
      "\"vectorizer\": \"text2vec-transformers\",\n",
      "\"properties\": [\n",
      "{\n",
      "\"name\": \"eventName\",\n",
      "\"dataType\": [\"text\"],\n",
      "\"description\": \"Name of the historical event\"\n",
      "},\n",
      "{\n",
      "\"name\": \"description\",\n",
      "\"dataType\": [\"text\"],\n",
      "\"description\": \"Detailed description of the event\"\n",
      "},\n",
      "{\n",
      "\"name\": \"year\",\n",
      "\"dataType\": [\"int\"],\n",
      "\"description\": \"Year the event occurred\"\n",
      "},\n",
      "{\n",
      "\"name\": \"hadSignificantImpact\",\n",
      "\"dataType\": [\"boolean\"],\n",
      "\"description\": \"Whether the event had a significant impact\"\n",
      "},\n",
      "{\n",
      "\"name\": \"involvedCountries\",\n",
      "\"dataType\": [\"Country\"],\n",
      "\"description\": \"Countries involved in the event\"\n",
      "}{\n",
      "\"class\": \"Country\",\n",
      "\"description\": \"Information about countries\",\n",
      "\"vectorIndexType\": \"hnsw\",\n",
      "\"vectorizer\": \"text2vec-transformers\",\n",
      "\"properties\": [\n",
      "{\n",
      "\"name\": \"countryName\",\n",
      "\"dataType\": [\"text\"],\n",
      "\"description\": \"Name of the country\"\n",
      "},\n",
      "{\n",
      "\"name\": \"population\",\n",
      "\"dataType\": [\"int\"],\n",
      "\"description\": \"Population of the country\"\n",
      "}}}\n",
      "\n",
      "## API reference\n",
      "`limit` returned objects\n",
      "\n",
      "Often, you will only want the top `n` results from the query. This can be achieved by setting a `limit` as shown below.\n",
      "\n",
      "```graphql\n",
      "{\n",
      "  Get {\n",
      "    JeopardyQuestion (\n",
      "      limit: 1\n",
      "    ) {\n",
      "      question\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "## Answer\n",
      "```graphql\n",
      "\n"
     ]
    }
   ],
   "source": [
    "default_prompt = \"\"\"\n",
    "## Instruction\n",
    "Your task is to write GraphQL for the Natural Language Query provided. Use the provided API reference and Schema to generate the GraphQL. The GraphQL should be valid for Weaviate.\n",
    "\n",
    "Only use the API reference to understand the syntax of the request.\n",
    "\n",
    "## Natural Language Query\n",
    "{nlcommand}\n",
    "\n",
    "## Schema\n",
    "{schema}\n",
    "\n",
    "## API reference\n",
    "{apiRef}\n",
    "\n",
    "## Answer\n",
    "```graphql\n",
    "\"\"\"\n",
    "\n",
    "prompt = params.get(\"prompt_template\", default_prompt)\n",
    "print(prompt.format_map(dataset[\"train\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27dc4a8a98784759a9aa928d37350b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import sys\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_path = \"/content/model/\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path, load_in_8bit=True, device_map=\"auto\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model_inputs = tokenizer([prompt.format_map(dataset[\"train\"][0])], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True, top_k=50, top_p=0.95, temperature=0.3)\n",
    "print(tokenizer.batch_decode(generated_ids)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
