{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hf_dataset': 'weaviate/WithoutRetrieval-SchemaSplit-Test-80',\n",
       " 'prompt_template': '## Instruction\\nYour task is to write GraphQL for the Natural Language Query provided. Use the provided API reference and Schema to generate the GraphQL. The GraphQL should be valid for Weaviate.\\n\\nOnly use the API reference to understand the syntax of the request.\\n\\n## Natural Language Query\\n{nlcommand}\\n\\n## Schema\\n{schema}\\n\\n## API reference\\n{apiRef}\\n\\n## Answer\\n```graphql\\n',\n",
       " 'push_to_hub': 'substratusai/wgql-WithRetrieval-SchemaSplit-Train-80'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "params = {}\n",
    "params_path = Path(\"/content/params.json\")\n",
    "if params_path.is_file():\n",
    "    with params_path.open(\"r\", encoding=\"UTF-8\") as params_file:\n",
    "        params = json.load(params_file)\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2c8cca70a446ea96a8f1f064fa50a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925591978aed441793754dedb1a6c2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878b2aa7d5ee4e76af46c7a56f1aa614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42fdf41012b49b282c3ee1a21cbafbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8897e24891ae40fbbe54928c33ac654b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output', 'nlcommand', 'apiRef', 'apiRefPath', 'schema', 'schemaPath'],\n",
       "        num_rows: 825\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hf_dataset = params.get(\"hf_dataset\")\n",
    "if hf_dataset:\n",
    "    dataset = load_dataset(hf_dataset)\n",
    "else:\n",
    "    dataset = load_dataset(\"json\", data_files=\"/content/data/*.json*\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Instruction\n",
      "Your task is to write GraphQL for the Natural Language Query provided. Use the provided API reference and Schema to generate the GraphQL. The GraphQL should be valid for Weaviate.\n",
      "\n",
      "Only use the API reference to understand the syntax of the request.\n",
      "\n",
      "## Natural Language Query\n",
      "```text\n",
      "Show me the event name, description, year, significant impact, and the countries involved with their population for the top 10 historical events.\n",
      "```\n",
      "\n",
      "## Schema\n",
      "{\n",
      "\"classes\": [\n",
      "{\n",
      "\"class\": \"HistoricalEvent\",\n",
      "\"description\": \"Information about historical events\",\n",
      "\"vectorIndexType\": \"hnsw\",\n",
      "\"vectorizer\": \"text2vec-transformers\",\n",
      "\"properties\": [\n",
      "{\n",
      "\"name\": \"eventName\",\n",
      "\"dataType\": [\"text\"],\n",
      "\"description\": \"Name of the historical event\"\n",
      "},\n",
      "{\n",
      "\"name\": \"description\",\n",
      "\"dataType\": [\"text\"],\n",
      "\"description\": \"Detailed description of the event\"\n",
      "},\n",
      "{\n",
      "\"name\": \"year\",\n",
      "\"dataType\": [\"int\"],\n",
      "\"description\": \"Year the event occurred\"\n",
      "},\n",
      "{\n",
      "\"name\": \"hadSignificantImpact\",\n",
      "\"dataType\": [\"boolean\"],\n",
      "\"description\": \"Whether the event had a significant impact\"\n",
      "},\n",
      "{\n",
      "\"name\": \"involvedCountries\",\n",
      "\"dataType\": [\"Country\"],\n",
      "\"description\": \"Countries involved in the event\"\n",
      "}{\n",
      "\"class\": \"Country\",\n",
      "\"description\": \"Information about countries\",\n",
      "\"vectorIndexType\": \"hnsw\",\n",
      "\"vectorizer\": \"text2vec-transformers\",\n",
      "\"properties\": [\n",
      "{\n",
      "\"name\": \"countryName\",\n",
      "\"dataType\": [\"text\"],\n",
      "\"description\": \"Name of the country\"\n",
      "},\n",
      "{\n",
      "\"name\": \"population\",\n",
      "\"dataType\": [\"int\"],\n",
      "\"description\": \"Population of the country\"\n",
      "}}}\n",
      "\n",
      "## API reference\n",
      "`limit` returned objects\n",
      "\n",
      "Often, you will only want the top `n` results from the query. This can be achieved by setting a `limit` as shown below.\n",
      "\n",
      "```graphql\n",
      "{\n",
      "  Get {\n",
      "    JeopardyQuestion (\n",
      "      limit: 1\n",
      "    ) {\n",
      "      question\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "## Answer\n",
      "```graphql\n",
      "\n"
     ]
    }
   ],
   "source": [
    "default_prompt = \"\"\"\n",
    "## Instruction\n",
    "Your task is to write GraphQL for the Natural Language Query provided. Use the provided API reference and Schema to generate the GraphQL. The GraphQL should be valid for Weaviate.\n",
    "\n",
    "Only use the API reference to understand the syntax of the request.\n",
    "\n",
    "## Natural Language Query\n",
    "{nlcommand}\n",
    "\n",
    "## Schema\n",
    "{schema}\n",
    "\n",
    "## API reference\n",
    "{apiRef}\n",
    "\n",
    "## Answer\n",
    "```graphql\n",
    "\"\"\"\n",
    "\n",
    "prompt = params.get(\"prompt_template\", default_prompt)\n",
    "print(prompt.format_map(dataset[\"train\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf875cc19b847b3b508737ce57f9c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b676467c4e4907af0eeb7ca25414b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec424dd120a406cb72f82692a333ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c54d3c672604f268e5d472e39b301fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24b9428fb8e41aebe414bb1ae3673bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05a505ab05840dfa400086c4effd5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/648 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23b12575354466f950c50e7e5172da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d6ce746ffb4b399118a770fe062d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d63b50bd6674a27a59d85da26947b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c1c4ddb62f481b9931554686a63e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b099aa8243a4dcda43e98f89d877ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1dde55069249dca00614fbd297cbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import sys\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_path = \"/content/model/\"\n",
    "model_id = params[\"push_to_hub\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id, device_map=\"auto\", trust_remote_code=True,\n",
    "            torch_dtype=torch.bfloat16, \n",
    "            use_flash_attention_2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 20 16:31:36 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA L4           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   49C    P0    29W /  72W |  13610MiB / 23034MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"do_sample\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"max_length\": 4096,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"temperature\": 0.6,\n",
       "  \"top_p\": 0.9\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7521])\n",
      "False\n",
      "False\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "stop_ids = torch.LongTensor(tokenizer.encode(\"```\", add_special_tokens=False))\n",
    "## Note the stop_ids aren't correct, for some reason there are multiple possible token IDs for ```\n",
    "## so instead we're using tensor([13940, 28832], device='cuda:0') as the stop_ids, because that's\n",
    "## what the model normally generates\n",
    "print(stop_ids)\n",
    "print(tokenizer.decode([8789]) == \"```\")\n",
    "print(tokenizer.decode([13940, 28832]) == \"```\")\n",
    "print(tokenizer.decode(tokenizer.encode(\"```\", add_special_tokens=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "class BacktickStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        if self.tokenizer.decode(input_ids[0][-2:]) == \"```\" or self.tokenizer.decode(input_ids[0][-1]) == \"```\":\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([BacktickStoppingCriteria(tokenizer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.bos_token_id = tokenizer.bos_token_id = 1\n",
    "model.config.eos_token_id = tokenizer.eos_token_id = 2\n",
    "model.config.pad_token_id = tokenizer.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Instruction\n",
      "Your task is to write GraphQL for the Natural Language Query provided. Use the provided API reference and Schema to generate the GraphQL. The GraphQL should be valid for Weaviate.\n",
      "\n",
      "Only use the API reference to understand the syntax of the request.\n",
      "\n",
      "## Natural Language Query\n",
      "```text\n",
      "Show me the event name, description, year, significant impact, and the countries involved with their population for the top 10 historical events.\n",
      "```\n",
      "\n",
      "## Schema\n",
      "{\n",
      "\"classes\": [\n",
      "{\n",
      "\"class\": \"HistoricalEvent\",\n",
      "\"description\": \"Information about historical events\",\n",
      "\"vectorIndexType\": \"hnsw\",\n",
      "\"vectorizer\": \"text2vec-transformers\",\n",
      "\"properties\": [\n",
      "{\n",
      "\"name\": \"eventName\",\n",
      "\"dataType\": [\"text\"],\n",
      "\"description\": \"Name of the historical event\"\n",
      "},\n",
      "{\n",
      "\"name\": \"description\",\n",
      "\"dataType\": [\"text\"],\n",
      "\"description\": \"Detailed description of the event\"\n",
      "},\n",
      "{\n",
      "\"name\": \"year\",\n",
      "\"dataType\": [\"int\"],\n",
      "\"description\": \"Year the event occurred\"\n",
      "},\n",
      "{\n",
      "\"name\": \"hadSignificantImpact\",\n",
      "\"dataType\": [\"boolean\"],\n",
      "\"description\": \"Whether the event had a significant impact\"\n",
      "},\n",
      "{\n",
      "\"name\": \"involvedCountries\",\n",
      "\"dataType\": [\"Country\"],\n",
      "\"description\": \"Countries involved in the event\"\n",
      "}{\n",
      "\"class\": \"Country\",\n",
      "\"description\": \"Information about countries\",\n",
      "\"vectorIndexType\": \"hnsw\",\n",
      "\"vectorizer\": \"text2vec-transformers\",\n",
      "\"properties\": [\n",
      "{\n",
      "\"name\": \"countryName\",\n",
      "\"dataType\": [\"text\"],\n",
      "\"description\": \"Name of the country\"\n",
      "},\n",
      "{\n",
      "\"name\": \"population\",\n",
      "\"dataType\": [\"int\"],\n",
      "\"description\": \"Population of the country\"\n",
      "}}}\n",
      "\n",
      "## API reference\n",
      "`limit` returned objects\n",
      "\n",
      "Often, you will only want the top `n` results from the query. This can be achieved by setting a `limit` as shown below.\n",
      "\n",
      "```graphql\n",
      "{\n",
      "  Get {\n",
      "    JeopardyQuestion (\n",
      "      limit: 1\n",
      "    ) {\n",
      "      question\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "## Answer\n",
      "```graphql\n",
      "{\n",
      "  Get {\n",
      "    HistoricalEvent (\n",
      "      limit: 10\n",
      "    ) {\n",
      "      eventName\n",
      "      description\n",
      "      year\n",
      "      hadSignificantImpact\n",
      "      involvedCountries {\n",
      "        ... on Country {\n",
      "          countryName\n",
      "          population\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "CPU times: user 6.57 s, sys: 709 ms, total: 7.28 s\n",
      "Wall time: 7.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "model_inputs = tokenizer([prompt.format_map(dataset[\"train\"][0])],\n",
    "                         return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(**model_inputs,\n",
    "                               max_new_tokens=300,\n",
    "                               stopping_criteria=stopping_criteria)\n",
    "\n",
    "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 534])\n",
      "{\n",
      "  Get {\n",
      "    HistoricalEvent (\n",
      "      limit: 10\n",
      "    ) {\n",
      "      eventName\n",
      "      description\n",
      "      year\n",
      "      hadSignificantImpact\n",
      "      involvedCountries {\n",
      "        ... on Country {\n",
      "          countryName\n",
      "          population\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_inputs[\"input_ids\"].shape)\n",
    "input_length = model_inputs[\"input_ids\"].shape[1]\n",
    "print(tokenizer.decode(generated_ids[0][input_length:], skip_special_tokens=True).strip(\"```\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference for 825 entries in dataset\n",
      "entry 1 of 825\n",
      "entry 2 of 825\n",
      "entry 3 of 825\n",
      "entry 4 of 825\n",
      "entry 5 of 825\n",
      "entry 6 of 825\n",
      "entry 7 of 825\n",
      "entry 8 of 825\n",
      "entry 9 of 825\n",
      "entry 10 of 825\n",
      "entry 11 of 825\n",
      "entry 12 of 825\n",
      "entry 13 of 825\n",
      "entry 14 of 825\n",
      "entry 15 of 825\n",
      "entry 16 of 825\n",
      "entry 17 of 825\n",
      "entry 18 of 825\n",
      "entry 19 of 825\n",
      "entry 20 of 825\n",
      "entry 21 of 825\n",
      "entry 22 of 825\n",
      "entry 23 of 825\n",
      "entry 24 of 825\n",
      "entry 25 of 825\n",
      "entry 26 of 825\n",
      "entry 27 of 825\n",
      "entry 28 of 825\n",
      "entry 29 of 825\n",
      "entry 30 of 825\n",
      "entry 31 of 825\n",
      "entry 32 of 825\n",
      "entry 33 of 825\n",
      "entry 34 of 825\n",
      "entry 35 of 825\n",
      "entry 36 of 825\n",
      "entry 37 of 825\n",
      "entry 38 of 825\n",
      "entry 39 of 825\n",
      "entry 40 of 825\n",
      "entry 41 of 825\n",
      "entry 42 of 825\n",
      "entry 43 of 825\n",
      "entry 44 of 825\n",
      "entry 45 of 825\n",
      "entry 46 of 825\n",
      "entry 47 of 825\n",
      "entry 48 of 825\n",
      "entry 49 of 825\n",
      "entry 50 of 825\n",
      "entry 51 of 825\n",
      "entry 52 of 825\n",
      "entry 53 of 825\n",
      "entry 54 of 825\n",
      "entry 55 of 825\n",
      "entry 56 of 825\n",
      "entry 57 of 825\n",
      "entry 58 of 825\n",
      "entry 59 of 825\n",
      "entry 60 of 825\n",
      "entry 61 of 825\n",
      "entry 62 of 825\n",
      "entry 63 of 825\n",
      "entry 64 of 825\n",
      "entry 65 of 825\n",
      "entry 66 of 825\n",
      "entry 67 of 825\n",
      "entry 68 of 825\n",
      "entry 69 of 825\n",
      "entry 70 of 825\n",
      "entry 71 of 825\n",
      "entry 72 of 825\n",
      "entry 73 of 825\n",
      "entry 74 of 825\n",
      "entry 75 of 825\n",
      "entry 76 of 825\n",
      "entry 77 of 825\n",
      "entry 78 of 825\n",
      "entry 79 of 825\n",
      "entry 80 of 825\n",
      "entry 81 of 825\n",
      "entry 82 of 825\n",
      "entry 83 of 825\n",
      "entry 84 of 825\n",
      "entry 85 of 825\n",
      "entry 86 of 825\n",
      "entry 87 of 825\n",
      "entry 88 of 825\n",
      "entry 89 of 825\n",
      "entry 90 of 825\n",
      "entry 91 of 825\n",
      "entry 92 of 825\n",
      "entry 93 of 825\n",
      "entry 94 of 825\n",
      "entry 95 of 825\n",
      "entry 96 of 825\n",
      "entry 97 of 825\n",
      "entry 98 of 825\n",
      "entry 99 of 825\n",
      "entry 100 of 825\n",
      "entry 101 of 825\n",
      "entry 102 of 825\n",
      "entry 103 of 825\n",
      "entry 104 of 825\n",
      "entry 105 of 825\n",
      "entry 106 of 825\n",
      "entry 107 of 825\n",
      "entry 108 of 825\n",
      "entry 109 of 825\n",
      "entry 110 of 825\n",
      "entry 111 of 825\n",
      "entry 112 of 825\n",
      "entry 113 of 825\n",
      "entry 114 of 825\n",
      "entry 115 of 825\n",
      "entry 116 of 825\n",
      "entry 117 of 825\n",
      "entry 118 of 825\n",
      "entry 119 of 825\n",
      "entry 120 of 825\n",
      "entry 121 of 825\n",
      "entry 122 of 825\n",
      "entry 123 of 825\n",
      "entry 124 of 825\n",
      "entry 125 of 825\n",
      "entry 126 of 825\n",
      "entry 127 of 825\n",
      "entry 128 of 825\n",
      "entry 129 of 825\n",
      "entry 130 of 825\n",
      "entry 131 of 825\n",
      "entry 132 of 825\n",
      "entry 133 of 825\n",
      "entry 134 of 825\n",
      "entry 135 of 825\n",
      "entry 136 of 825\n",
      "entry 137 of 825\n",
      "entry 138 of 825\n",
      "entry 139 of 825\n",
      "entry 140 of 825\n",
      "entry 141 of 825\n",
      "entry 142 of 825\n",
      "entry 143 of 825\n",
      "entry 144 of 825\n",
      "entry 145 of 825\n",
      "entry 146 of 825\n",
      "entry 147 of 825\n",
      "entry 148 of 825\n",
      "entry 149 of 825\n",
      "entry 150 of 825\n",
      "entry 151 of 825\n",
      "entry 152 of 825\n",
      "entry 153 of 825\n",
      "entry 154 of 825\n",
      "entry 155 of 825\n",
      "entry 156 of 825\n",
      "entry 157 of 825\n",
      "entry 158 of 825\n",
      "entry 159 of 825\n",
      "entry 160 of 825\n",
      "entry 161 of 825\n",
      "entry 162 of 825\n",
      "entry 163 of 825\n",
      "entry 164 of 825\n",
      "entry 165 of 825\n",
      "entry 166 of 825\n",
      "entry 167 of 825\n",
      "entry 168 of 825\n",
      "entry 169 of 825\n",
      "entry 170 of 825\n",
      "entry 171 of 825\n",
      "entry 172 of 825\n",
      "entry 173 of 825\n",
      "entry 174 of 825\n",
      "entry 175 of 825\n",
      "entry 176 of 825\n",
      "entry 177 of 825\n",
      "entry 178 of 825\n",
      "entry 179 of 825\n",
      "entry 180 of 825\n",
      "entry 181 of 825\n",
      "entry 182 of 825\n",
      "entry 183 of 825\n",
      "entry 184 of 825\n",
      "entry 185 of 825\n",
      "entry 186 of 825\n",
      "entry 187 of 825\n",
      "entry 188 of 825\n",
      "entry 189 of 825\n",
      "entry 190 of 825\n",
      "entry 191 of 825\n",
      "entry 192 of 825\n",
      "entry 193 of 825\n",
      "entry 194 of 825\n",
      "entry 195 of 825\n",
      "entry 196 of 825\n",
      "entry 197 of 825\n",
      "entry 198 of 825\n",
      "entry 199 of 825\n",
      "entry 200 of 825\n",
      "entry 201 of 825\n",
      "entry 202 of 825\n",
      "entry 203 of 825\n",
      "entry 204 of 825\n",
      "entry 205 of 825\n",
      "entry 206 of 825\n",
      "entry 207 of 825\n",
      "entry 208 of 825\n",
      "entry 209 of 825\n",
      "entry 210 of 825\n",
      "entry 211 of 825\n",
      "entry 212 of 825\n",
      "entry 213 of 825\n",
      "entry 214 of 825\n",
      "entry 215 of 825\n",
      "entry 216 of 825\n",
      "entry 217 of 825\n",
      "entry 218 of 825\n",
      "entry 219 of 825\n",
      "entry 220 of 825\n",
      "entry 221 of 825\n",
      "entry 222 of 825\n",
      "entry 223 of 825\n",
      "entry 224 of 825\n",
      "entry 225 of 825\n",
      "entry 226 of 825\n",
      "entry 227 of 825\n",
      "entry 228 of 825\n",
      "entry 229 of 825\n",
      "entry 230 of 825\n",
      "entry 231 of 825\n",
      "entry 232 of 825\n",
      "entry 233 of 825\n",
      "entry 234 of 825\n",
      "entry 235 of 825\n",
      "entry 236 of 825\n",
      "entry 237 of 825\n",
      "entry 238 of 825\n",
      "entry 239 of 825\n",
      "entry 240 of 825\n",
      "entry 241 of 825\n",
      "entry 242 of 825\n",
      "entry 243 of 825\n",
      "entry 244 of 825\n",
      "entry 245 of 825\n",
      "entry 246 of 825\n",
      "entry 247 of 825\n",
      "entry 248 of 825\n",
      "entry 249 of 825\n",
      "entry 250 of 825\n",
      "entry 251 of 825\n",
      "entry 252 of 825\n",
      "entry 253 of 825\n",
      "entry 254 of 825\n",
      "entry 255 of 825\n",
      "entry 256 of 825\n",
      "entry 257 of 825\n",
      "entry 258 of 825\n",
      "entry 259 of 825\n",
      "entry 260 of 825\n",
      "entry 261 of 825\n",
      "entry 262 of 825\n",
      "entry 263 of 825\n",
      "entry 264 of 825\n",
      "entry 265 of 825\n",
      "entry 266 of 825\n",
      "entry 267 of 825\n",
      "entry 268 of 825\n",
      "entry 269 of 825\n",
      "entry 270 of 825\n",
      "entry 271 of 825\n",
      "entry 272 of 825\n",
      "entry 273 of 825\n",
      "entry 274 of 825\n",
      "entry 275 of 825\n",
      "entry 276 of 825\n",
      "entry 277 of 825\n",
      "entry 278 of 825\n",
      "entry 279 of 825\n",
      "entry 280 of 825\n",
      "entry 281 of 825\n",
      "entry 282 of 825\n",
      "entry 283 of 825\n",
      "entry 284 of 825\n",
      "entry 285 of 825\n",
      "entry 286 of 825\n",
      "entry 287 of 825\n",
      "entry 288 of 825\n",
      "entry 289 of 825\n",
      "entry 290 of 825\n",
      "entry 291 of 825\n",
      "entry 292 of 825\n",
      "entry 293 of 825\n",
      "entry 294 of 825\n",
      "entry 295 of 825\n",
      "entry 296 of 825\n",
      "entry 297 of 825\n",
      "entry 298 of 825\n",
      "entry 299 of 825\n",
      "entry 300 of 825\n",
      "entry 301 of 825\n",
      "entry 302 of 825\n",
      "entry 303 of 825\n",
      "entry 304 of 825\n",
      "entry 305 of 825\n",
      "entry 306 of 825\n",
      "entry 307 of 825\n",
      "entry 308 of 825\n",
      "entry 309 of 825\n",
      "entry 310 of 825\n",
      "entry 311 of 825\n",
      "entry 312 of 825\n",
      "entry 313 of 825\n",
      "entry 314 of 825\n",
      "entry 315 of 825\n",
      "entry 316 of 825\n",
      "entry 317 of 825\n",
      "entry 318 of 825\n",
      "entry 319 of 825\n",
      "entry 320 of 825\n",
      "entry 321 of 825\n",
      "entry 322 of 825\n",
      "entry 323 of 825\n",
      "entry 324 of 825\n",
      "entry 325 of 825\n",
      "entry 326 of 825\n",
      "entry 327 of 825\n",
      "entry 328 of 825\n",
      "entry 329 of 825\n",
      "entry 330 of 825\n",
      "entry 331 of 825\n",
      "entry 332 of 825\n",
      "entry 333 of 825\n",
      "entry 334 of 825\n",
      "entry 335 of 825\n",
      "entry 336 of 825\n",
      "entry 337 of 825\n",
      "entry 338 of 825\n",
      "entry 339 of 825\n",
      "entry 340 of 825\n",
      "entry 341 of 825\n",
      "entry 342 of 825\n",
      "entry 343 of 825\n",
      "entry 344 of 825\n",
      "entry 345 of 825\n",
      "entry 346 of 825\n",
      "entry 347 of 825\n",
      "entry 348 of 825\n",
      "entry 349 of 825\n",
      "entry 350 of 825\n",
      "entry 351 of 825\n",
      "entry 352 of 825\n",
      "entry 353 of 825\n",
      "entry 354 of 825\n",
      "entry 355 of 825\n",
      "entry 356 of 825\n",
      "entry 357 of 825\n",
      "entry 358 of 825\n",
      "entry 359 of 825\n",
      "entry 360 of 825\n",
      "entry 361 of 825\n",
      "entry 362 of 825\n",
      "entry 363 of 825\n",
      "entry 364 of 825\n",
      "entry 365 of 825\n",
      "entry 366 of 825\n",
      "entry 367 of 825\n",
      "entry 368 of 825\n",
      "entry 369 of 825\n",
      "entry 370 of 825\n",
      "entry 371 of 825\n",
      "entry 372 of 825\n",
      "entry 373 of 825\n",
      "entry 374 of 825\n",
      "entry 375 of 825\n",
      "entry 376 of 825\n",
      "entry 377 of 825\n",
      "entry 378 of 825\n",
      "entry 379 of 825\n",
      "entry 380 of 825\n",
      "entry 381 of 825\n",
      "entry 382 of 825\n",
      "entry 383 of 825\n",
      "entry 384 of 825\n",
      "entry 385 of 825\n",
      "entry 386 of 825\n",
      "entry 387 of 825\n",
      "entry 388 of 825\n",
      "entry 389 of 825\n",
      "entry 390 of 825\n",
      "entry 391 of 825\n",
      "entry 392 of 825\n",
      "entry 393 of 825\n",
      "entry 394 of 825\n",
      "entry 395 of 825\n",
      "entry 396 of 825\n",
      "entry 397 of 825\n",
      "entry 398 of 825\n",
      "entry 399 of 825\n",
      "entry 400 of 825\n",
      "entry 401 of 825\n",
      "entry 402 of 825\n",
      "entry 403 of 825\n",
      "entry 404 of 825\n",
      "entry 405 of 825\n",
      "entry 406 of 825\n",
      "entry 407 of 825\n",
      "entry 408 of 825\n",
      "entry 409 of 825\n",
      "entry 410 of 825\n",
      "entry 411 of 825\n",
      "entry 412 of 825\n",
      "entry 413 of 825\n",
      "entry 414 of 825\n",
      "entry 415 of 825\n",
      "entry 416 of 825\n",
      "entry 417 of 825\n",
      "entry 418 of 825\n",
      "entry 419 of 825\n",
      "entry 420 of 825\n",
      "entry 421 of 825\n",
      "entry 422 of 825\n",
      "entry 423 of 825\n",
      "entry 424 of 825\n",
      "entry 425 of 825\n",
      "entry 426 of 825\n",
      "entry 427 of 825\n",
      "entry 428 of 825\n",
      "entry 429 of 825\n",
      "entry 430 of 825\n",
      "entry 431 of 825\n",
      "entry 432 of 825\n",
      "entry 433 of 825\n",
      "entry 434 of 825\n",
      "entry 435 of 825\n",
      "entry 436 of 825\n",
      "entry 437 of 825\n",
      "entry 438 of 825\n",
      "entry 439 of 825\n",
      "entry 440 of 825\n",
      "entry 441 of 825\n",
      "entry 442 of 825\n",
      "entry 443 of 825\n",
      "entry 444 of 825\n",
      "entry 445 of 825\n",
      "entry 446 of 825\n",
      "entry 447 of 825\n",
      "entry 448 of 825\n",
      "entry 449 of 825\n",
      "entry 450 of 825\n",
      "entry 451 of 825\n",
      "entry 452 of 825\n",
      "entry 453 of 825\n",
      "entry 454 of 825\n",
      "entry 455 of 825\n",
      "entry 456 of 825\n",
      "entry 457 of 825\n",
      "entry 458 of 825\n",
      "entry 459 of 825\n",
      "entry 460 of 825\n",
      "entry 461 of 825\n",
      "entry 462 of 825\n",
      "entry 463 of 825\n",
      "entry 464 of 825\n",
      "entry 465 of 825\n",
      "entry 466 of 825\n",
      "entry 467 of 825\n",
      "entry 468 of 825\n",
      "entry 469 of 825\n",
      "entry 470 of 825\n",
      "entry 471 of 825\n",
      "entry 472 of 825\n",
      "entry 473 of 825\n",
      "entry 474 of 825\n",
      "entry 475 of 825\n",
      "entry 476 of 825\n",
      "entry 477 of 825\n",
      "entry 478 of 825\n",
      "entry 479 of 825\n",
      "entry 480 of 825\n",
      "entry 481 of 825\n",
      "entry 482 of 825\n",
      "entry 483 of 825\n",
      "entry 484 of 825\n",
      "entry 485 of 825\n",
      "entry 486 of 825\n",
      "entry 487 of 825\n",
      "entry 488 of 825\n",
      "entry 489 of 825\n",
      "entry 490 of 825\n",
      "entry 491 of 825\n",
      "entry 492 of 825\n",
      "entry 493 of 825\n",
      "entry 494 of 825\n",
      "entry 495 of 825\n",
      "entry 496 of 825\n",
      "entry 497 of 825\n",
      "entry 498 of 825\n",
      "entry 499 of 825\n",
      "entry 500 of 825\n",
      "entry 501 of 825\n",
      "entry 502 of 825\n",
      "entry 503 of 825\n",
      "entry 504 of 825\n",
      "entry 505 of 825\n",
      "entry 506 of 825\n",
      "entry 507 of 825\n",
      "entry 508 of 825\n",
      "entry 509 of 825\n",
      "entry 510 of 825\n",
      "entry 511 of 825\n",
      "entry 512 of 825\n",
      "entry 513 of 825\n",
      "entry 514 of 825\n",
      "entry 515 of 825\n",
      "entry 516 of 825\n",
      "entry 517 of 825\n",
      "entry 518 of 825\n",
      "entry 519 of 825\n",
      "entry 520 of 825\n",
      "entry 521 of 825\n",
      "entry 522 of 825\n",
      "entry 523 of 825\n",
      "entry 524 of 825\n",
      "entry 525 of 825\n",
      "entry 526 of 825\n",
      "entry 527 of 825\n",
      "entry 528 of 825\n",
      "entry 529 of 825\n",
      "entry 530 of 825\n",
      "entry 531 of 825\n",
      "entry 532 of 825\n",
      "entry 533 of 825\n",
      "entry 534 of 825\n",
      "entry 535 of 825\n",
      "entry 536 of 825\n",
      "entry 537 of 825\n",
      "entry 538 of 825\n",
      "entry 539 of 825\n",
      "entry 540 of 825\n",
      "entry 541 of 825\n",
      "entry 542 of 825\n",
      "entry 543 of 825\n",
      "entry 544 of 825\n",
      "entry 545 of 825\n",
      "entry 546 of 825\n",
      "entry 547 of 825\n",
      "entry 548 of 825\n",
      "entry 549 of 825\n",
      "entry 550 of 825\n",
      "entry 551 of 825\n",
      "entry 552 of 825\n",
      "entry 553 of 825\n",
      "entry 554 of 825\n",
      "entry 555 of 825\n",
      "entry 556 of 825\n",
      "entry 557 of 825\n",
      "entry 558 of 825\n",
      "entry 559 of 825\n",
      "entry 560 of 825\n",
      "entry 561 of 825\n",
      "entry 562 of 825\n",
      "entry 563 of 825\n",
      "entry 564 of 825\n",
      "entry 565 of 825\n",
      "entry 566 of 825\n",
      "entry 567 of 825\n",
      "entry 568 of 825\n",
      "entry 569 of 825\n",
      "entry 570 of 825\n",
      "entry 571 of 825\n",
      "entry 572 of 825\n",
      "entry 573 of 825\n",
      "entry 574 of 825\n",
      "entry 575 of 825\n",
      "entry 576 of 825\n",
      "entry 577 of 825\n",
      "entry 578 of 825\n",
      "entry 579 of 825\n",
      "entry 580 of 825\n",
      "entry 581 of 825\n",
      "entry 582 of 825\n",
      "entry 583 of 825\n",
      "entry 584 of 825\n",
      "entry 585 of 825\n",
      "entry 586 of 825\n",
      "entry 587 of 825\n",
      "entry 588 of 825\n",
      "entry 589 of 825\n",
      "entry 590 of 825\n",
      "entry 591 of 825\n",
      "entry 592 of 825\n",
      "entry 593 of 825\n",
      "entry 594 of 825\n",
      "entry 595 of 825\n",
      "entry 596 of 825\n",
      "entry 597 of 825\n",
      "entry 598 of 825\n",
      "entry 599 of 825\n",
      "entry 600 of 825\n",
      "entry 601 of 825\n",
      "entry 602 of 825\n",
      "entry 603 of 825\n",
      "entry 604 of 825\n",
      "entry 605 of 825\n",
      "entry 606 of 825\n",
      "entry 607 of 825\n",
      "entry 608 of 825\n",
      "entry 609 of 825\n",
      "entry 610 of 825\n",
      "entry 611 of 825\n",
      "entry 612 of 825\n",
      "entry 613 of 825\n",
      "entry 614 of 825\n",
      "entry 615 of 825\n",
      "entry 616 of 825\n",
      "entry 617 of 825\n",
      "entry 618 of 825\n",
      "entry 619 of 825\n",
      "entry 620 of 825\n",
      "entry 621 of 825\n",
      "entry 622 of 825\n",
      "entry 623 of 825\n",
      "entry 624 of 825\n",
      "entry 625 of 825\n",
      "entry 626 of 825\n",
      "entry 627 of 825\n",
      "entry 628 of 825\n",
      "entry 629 of 825\n",
      "entry 630 of 825\n",
      "entry 631 of 825\n",
      "entry 632 of 825\n",
      "entry 633 of 825\n",
      "entry 634 of 825\n",
      "entry 635 of 825\n",
      "entry 636 of 825\n",
      "entry 637 of 825\n",
      "entry 638 of 825\n",
      "entry 639 of 825\n",
      "entry 640 of 825\n",
      "entry 641 of 825\n",
      "entry 642 of 825\n",
      "entry 643 of 825\n",
      "entry 644 of 825\n",
      "entry 645 of 825\n",
      "entry 646 of 825\n",
      "entry 647 of 825\n",
      "entry 648 of 825\n",
      "entry 649 of 825\n",
      "entry 650 of 825\n",
      "entry 651 of 825\n",
      "entry 652 of 825\n",
      "entry 653 of 825\n",
      "entry 654 of 825\n",
      "entry 655 of 825\n",
      "entry 656 of 825\n",
      "entry 657 of 825\n",
      "entry 658 of 825\n",
      "entry 659 of 825\n",
      "entry 660 of 825\n",
      "entry 661 of 825\n",
      "entry 662 of 825\n",
      "entry 663 of 825\n",
      "entry 664 of 825\n",
      "entry 665 of 825\n",
      "entry 666 of 825\n",
      "entry 667 of 825\n",
      "entry 668 of 825\n",
      "entry 669 of 825\n",
      "entry 670 of 825\n",
      "entry 671 of 825\n",
      "entry 672 of 825\n",
      "entry 673 of 825\n",
      "entry 674 of 825\n",
      "entry 675 of 825\n",
      "entry 676 of 825\n",
      "entry 677 of 825\n",
      "entry 678 of 825\n",
      "entry 679 of 825\n",
      "entry 680 of 825\n",
      "entry 681 of 825\n",
      "entry 682 of 825\n",
      "entry 683 of 825\n",
      "entry 684 of 825\n",
      "entry 685 of 825\n",
      "entry 686 of 825\n",
      "entry 687 of 825\n",
      "entry 688 of 825\n",
      "entry 689 of 825\n",
      "entry 690 of 825\n",
      "entry 691 of 825\n",
      "entry 692 of 825\n",
      "entry 693 of 825\n",
      "entry 694 of 825\n",
      "entry 695 of 825\n",
      "entry 696 of 825\n",
      "entry 697 of 825\n",
      "entry 698 of 825\n",
      "entry 699 of 825\n",
      "entry 700 of 825\n",
      "entry 701 of 825\n",
      "entry 702 of 825\n",
      "entry 703 of 825\n",
      "entry 704 of 825\n",
      "entry 705 of 825\n",
      "entry 706 of 825\n",
      "entry 707 of 825\n",
      "entry 708 of 825\n",
      "entry 709 of 825\n",
      "entry 710 of 825\n",
      "entry 711 of 825\n",
      "entry 712 of 825\n",
      "entry 713 of 825\n",
      "entry 714 of 825\n",
      "entry 715 of 825\n",
      "entry 716 of 825\n",
      "entry 717 of 825\n",
      "entry 718 of 825\n",
      "entry 719 of 825\n",
      "entry 720 of 825\n",
      "entry 721 of 825\n",
      "entry 722 of 825\n",
      "entry 723 of 825\n",
      "entry 724 of 825\n",
      "entry 725 of 825\n",
      "entry 726 of 825\n",
      "entry 727 of 825\n",
      "entry 728 of 825\n",
      "entry 729 of 825\n",
      "entry 730 of 825\n",
      "entry 731 of 825\n",
      "entry 732 of 825\n",
      "entry 733 of 825\n",
      "entry 734 of 825\n",
      "entry 735 of 825\n",
      "entry 736 of 825\n",
      "entry 737 of 825\n",
      "entry 738 of 825\n",
      "entry 739 of 825\n",
      "entry 740 of 825\n",
      "entry 741 of 825\n",
      "entry 742 of 825\n",
      "entry 743 of 825\n",
      "entry 744 of 825\n",
      "entry 745 of 825\n",
      "entry 746 of 825\n",
      "entry 747 of 825\n",
      "entry 748 of 825\n",
      "entry 749 of 825\n",
      "entry 750 of 825\n",
      "entry 751 of 825\n",
      "entry 752 of 825\n",
      "entry 753 of 825\n",
      "entry 754 of 825\n",
      "entry 755 of 825\n",
      "entry 756 of 825\n",
      "entry 757 of 825\n",
      "entry 758 of 825\n",
      "entry 759 of 825\n",
      "entry 760 of 825\n",
      "entry 761 of 825\n",
      "entry 762 of 825\n",
      "entry 763 of 825\n",
      "entry 764 of 825\n",
      "entry 765 of 825\n",
      "entry 766 of 825\n",
      "entry 767 of 825\n",
      "entry 768 of 825\n",
      "entry 769 of 825\n",
      "entry 770 of 825\n",
      "entry 771 of 825\n",
      "entry 772 of 825\n",
      "entry 773 of 825\n",
      "entry 774 of 825\n",
      "entry 775 of 825\n",
      "entry 776 of 825\n",
      "entry 777 of 825\n",
      "entry 778 of 825\n",
      "entry 779 of 825\n",
      "entry 780 of 825\n",
      "entry 781 of 825\n",
      "entry 782 of 825\n",
      "entry 783 of 825\n",
      "entry 784 of 825\n",
      "entry 785 of 825\n",
      "entry 786 of 825\n",
      "entry 787 of 825\n",
      "entry 788 of 825\n",
      "entry 789 of 825\n",
      "entry 790 of 825\n",
      "entry 791 of 825\n",
      "entry 792 of 825\n",
      "entry 793 of 825\n",
      "entry 794 of 825\n",
      "entry 795 of 825\n",
      "entry 796 of 825\n",
      "entry 797 of 825\n",
      "entry 798 of 825\n",
      "entry 799 of 825\n",
      "entry 800 of 825\n",
      "entry 801 of 825\n",
      "entry 802 of 825\n",
      "entry 803 of 825\n",
      "entry 804 of 825\n",
      "entry 805 of 825\n",
      "entry 806 of 825\n",
      "entry 807 of 825\n",
      "entry 808 of 825\n",
      "entry 809 of 825\n",
      "entry 810 of 825\n",
      "entry 811 of 825\n",
      "entry 812 of 825\n",
      "entry 813 of 825\n",
      "entry 814 of 825\n",
      "entry 815 of 825\n",
      "entry 816 of 825\n",
      "entry 817 of 825\n",
      "entry 818 of 825\n",
      "entry 819 of 825\n",
      "entry 820 of 825\n",
      "entry 821 of 825\n",
      "entry 822 of 825\n",
      "entry 823 of 825\n",
      "entry 824 of 825\n",
      "entry 825 of 825\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "dataset_size = len(dataset[\"train\"])\n",
    "output_path = \"/content/artifacts/test-output.json\"\n",
    "entries = []\n",
    "print(f\"Running inference for {dataset_size} entries in dataset\")\n",
    "for i in range(dataset_size):\n",
    "    print(f\"entry {i+1} of {dataset_size}\")\n",
    "    entry = dataset[\"train\"][i]\n",
    "    model_inputs = tokenizer([prompt.format_map(entry)],\n",
    "                         return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "\n",
    "    generated_ids = model.generate(**model_inputs,\n",
    "                               max_new_tokens=300,\n",
    "                               stopping_criteria=stopping_criteria)\n",
    "    input_length = model_inputs[\"input_ids\"].shape[1]\n",
    "    output = tokenizer.decode(generated_ids[0][input_length:], skip_special_tokens=True)\n",
    "    entry[\"modelOutput\"] = output.strip(\"```\")\n",
    "    entries.append(entry)\n",
    "\n",
    "    with open(output_path, 'a') as file:\n",
    "        json.dump(entry, file)\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the test dataset with model output in the original HuggingFace Model repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "repo_id = params.get(\"push_to_hub\")\n",
    "if repo_id:\n",
    "    hf_api = HfApi()\n",
    "    hf_api.upload_file(\n",
    "            path_or_fileobj=Path(output_path),\n",
    "            path_in_repo=Path(output_path).name,\n",
    "            repo_id=repo_id,\n",
    "    )\n",
    "    logs_path = Path(\"/content/artifacts/eval.ipynb\")\n",
    "    if logs_path.exists():\n",
    "        hf_api.upload_file(\n",
    "            path_or_fileobj=logs_path,\n",
    "            path_in_repo=logs_path.name,\n",
    "            repo_id=repo_id,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the model output on a live Weaviate cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /root/.cache/weaviate-embedded: process ID 7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2023-10-21T00:13:16Z\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2023-10-21T00:13:16Z\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2023-10-21T00:13:16Z\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2023-10-21T00:13:16Z\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:6666\",\"time\":\"2023-10-21T00:13:16Z\"}\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "\n",
    "client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"classes\": [\n",
      "      {\n",
      "        \"class\": \"HistoricalEvent\",\n",
      "        \"description\": \"Information about historical events\",\n",
      "        \"vectorIndexType\": \"hnsw\",\n",
      "        \"vectorizer\": \"text2vec-transformers\",\n",
      "        \"properties\": [\n",
      "          {\n",
      "            \"name\": \"eventName\",\n",
      "            \"dataType\": [\"text\"],\n",
      "            \"description\": \"Name of the historical event\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"description\",\n",
      "            \"dataType\": [\"text\"],\n",
      "            \"description\": \"Detailed description of the event\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"year\",\n",
      "            \"dataType\": [\"int\"],\n",
      "            \"description\": \"Year the event occurred\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"hadSignificantImpact\",\n",
      "            \"dataType\": [\"boolean\"],\n",
      "            \"description\": \"Whether the event had a significant impact\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"involvedCountries\",\n",
      "            \"dataType\": [\"Country\"],\n",
      "            \"description\": \"Countries involved in the event\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"class\": \"Country\",\n",
      "        \"description\": \"Information about countries\",\n",
      "        \"vectorIndexType\": \"hnsw\",\n",
      "        \"vectorizer\": \"text2vec-transformers\",\n",
      "        \"properties\": [\n",
      "          {\n",
      "            \"name\": \"countryName\",\n",
      "            \"dataType\": [\"text\"],\n",
      "            \"description\": \"Name of the country\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"population\",\n",
      "            \"dataType\": [\"int\"],\n",
      "            \"description\": \"Population of the country\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output', 'nlcommand', 'apiRef', 'apiRefPath', 'schema', 'schemaPath'],\n",
       "        num_rows: 825\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! cat ToySchemas/{dataset[\"train\"][0][\"schemaPath\"]}\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"historicalevent_3GCGHMH4c4Em\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-10-21T00:18:03Z\",\"took\":90086}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"country_DHJOHEyNcXoH\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-10-21T00:18:03Z\",\"took\":86369}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': {'Get': {'HistoricalEvent': []}}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "def json_reader(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as api_ref_fh:\n",
    "        data = json.load(api_ref_fh)\n",
    "    return data\n",
    "\n",
    "def remove_vectorizer(classes: list[Dict]) -> list[Dict]:\n",
    "    new_list = []\n",
    "    for c in classes:\n",
    "        if \"vectorizer\" in c:\n",
    "            del c[\"vectorizer\"]\n",
    "        new_list.append(c)\n",
    "    return new_list\n",
    "\n",
    "def didItExecute(schemaPath, modelOutput):\n",
    "    client.schema.delete_all()\n",
    "    schema = json_reader(f'ToySchemas/{schemaPath}')\n",
    "    schema[\"classes\"] = remove_vectorizer(schema[\"classes\"])\n",
    "    client.schema.create(schema)\n",
    "    WeaviateResponse = client.query.raw(modelOutput)\n",
    "    return WeaviateResponse\n",
    "\n",
    "sample = entries[0]\n",
    "didItExecute(sample[\"schemaPath\"], sample[\"modelOutput\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "counter = 1\n",
    "successfulQueries = []\n",
    "failedQueries = []\n",
    "failedAPIsCount = {}\n",
    "failedSchemasCount = {}\n",
    "for idx, example in enumerate(entries):\n",
    "    failed = False\n",
    "    modelQuery = example[\"modelOutput\"]\n",
    "\n",
    "    weaviateResponse = didItExecute(example[\"schemaPath\"], modelQuery)\n",
    "\n",
    "    if \"errors\" in weaviateResponse.keys():\n",
    "        failed = True\n",
    "\n",
    "    if failed:\n",
    "        print(\"FAILED! FAILED! FAILED! \\n\")\n",
    "        print(idx)\n",
    "        failedQueries.append(example)\n",
    "        # Update failed Schema tracker\n",
    "        if example[\"schemaPath\"] in failedSchemasCount.keys():\n",
    "            failedSchemasCount[example[\"schemaPath\"]] += 1\n",
    "        else:\n",
    "            failedSchemasCount[example[\"schemaPath\"]] = 1\n",
    "        # Update API tracker\n",
    "        if example[\"apiRefPath\"] in failedAPIsCount.keys():\n",
    "            failedAPIsCount[example[\"apiRefPath\"]] += 1\n",
    "        else:\n",
    "            failedAPIsCount[example[\"apiRefPath\"]] = 1\n",
    "    else:\n",
    "        successfulQueries.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493 Queries successfully executed!\n",
      "332 Queries failed to execute!\n",
      "FAILED API Count \n",
      "\n",
      "{'get-hybrid-explainScore.txt': 17, 'get-hybrid-with-autocut.txt': 20, 'get-hybrid-alpha.txt': 20, 'get-nearText.txt': 20, 'get-nearText-with-distance.txt': 20, 'aggregate-nearText-with-distance.txt': 8, 'get-hybrid-alpha-properties.txt': 20, 'aggregate-nearText-with-limit.txt': 14, 'get-hybrid-weight-properties.txt': 20, 'get-hybrid.txt': 20, 'get-where-with-search.txt': 20, 'get-hybrid-with-where.txt': 20, 'get-hybrid-with-limit.txt': 20, 'get-hybrid-fusionType.txt': 20, 'get-nearText-with-autocut.txt': 20, 'get-nearText-with-where.txt': 20, 'get-nearText-with-limit.txt': 20, 'get-reranking-vector-search.txt': 13}\n",
      "FAILE SCHEMA COUNT \n",
      "\n",
      "{'historicalevent.json': 16, 'musicalinstrument.json': 17, 'weatherstation.json': 17, 'AIModels.json': 17, 'outdoorgear.json': 17, 'startups.json': 18, 'videogame.json': 18, 'books.json': 17, 'craftbeer.json': 17, 'chemicals.json': 18, 'pharmaceuticals.json': 15, 'filmfestivals.json': 15, 'boats.json': 16, 'pets.json': 18, 'spaceexploration.json': 17, 'nonprofits.json': 17, 'augmentedreality.json': 16, 'virtualreality.json': 14, 'nationalparks.json': 15, 'jewelry.json': 17}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(successfulQueries)} Queries successfully executed!\")\n",
    "print(f\"{len(failedQueries)} Queries failed to execute!\")\n",
    "print(\"FAILED API Count \\n\")\n",
    "print(failedAPIsCount)\n",
    "print(\"FAILE SCHEMA COUNT \\n\")\n",
    "print(failedSchemasCount)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
